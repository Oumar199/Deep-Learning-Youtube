import numpy as np


def back_propagation(y, activations, parametres):

    m = y.shape[1]
    C = len(parametres) // 2

    dZ = activations["A" + str(C)] - y

    gradients = {}

    for c in reversed(range(1, C + 1)):
        gradients["dW" + str(c)] = 1 / m * np.dot(dZ, activations["A" + str(c - 1)].T)
        gradients["db" + str(c)] = 1 / m * np.sum(dZ, axis=1, keepdims=True)
        if c > 1:
            dZ = (
                np.dot(parametres["W" + str(c)].T, dZ)
                * activations["A" + str(c - 1)]
                * (1 - activations["A" + str(c - 1)])
            )

    return gradients
